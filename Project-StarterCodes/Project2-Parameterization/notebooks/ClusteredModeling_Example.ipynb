{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustered Approach to Ocean Mixing Parameterization\n",
    "\n",
    "This notebook demonstrates the new class-based architecture for clustered ocean mixing parameterization. It implements both input-based clustering and shape function (output) clustering approaches.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "1. **Modular Design**: Easy to swap clustering algorithms, networks, and training parameters\n",
    "2. **Multiple Approaches**: Supports both input-based and output-based clustering\n",
    "3. **Visualization Tools**: Comprehensive tools for visualizing clusters, performance, and shape functions\n",
    "4. **Clean API**: Consistent interface for training, prediction, and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Setup notebook environment\n",
    "today = datetime.today()\n",
    "np.random.seed(100)\n",
    "torch.manual_seed(100)\n",
    "\n",
    "# Fix paths\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "os.chdir(parent_dir)\n",
    "cwd = parent_dir\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Import custom modules\n",
    "import lib.func_file as ff\n",
    "from lib.ocean_models import OceanMixingNN, OceanMixingResidualNN\n",
    "from lib.clustered_models import (\n",
    "    InputClusteredModel, \n",
    "    OutputClusteredModel,\n",
    "    ClusterModelVisualizer\n",
    ")\n",
    "\n",
    "# Set up directories\n",
    "cwd_data = cwd + '/Data/'\n",
    "cwd_output = cwd + '/output/'\n",
    "os.makedirs(cwd_output, exist_ok=True)\n",
    "\n",
    "# Set device for PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data\n",
    "\n",
    "Following the same data loading approach from the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GOTM training data produced by Sane et al. 2023\n",
    "store = 'https://nyu1.osn.mghpcc.org/leap-pangeo-manual/GOTM/sf_training_data.zarr'\n",
    "d = xr.open_dataset(store, engine='zarr', chunks={})\n",
    "\n",
    "# Coriolis parameter calculation\n",
    "def corio(lat):\n",
    "    return 2*(2*np.pi/(24*60*60)) * np.sin(lat*(np.pi/180))\n",
    "\n",
    "# Extract variables\n",
    "l0 = corio(d['l'][:])\n",
    "b00 = d['b0'][:]\n",
    "ustar0 = d['ustar'][:]\n",
    "h0 = d['h'][:]\n",
    "lat0 = d['lat'][:]\n",
    "heat0 = d['heat'][:]\n",
    "tx0 = d['tx'][:]\n",
    "tx0 = np.round(tx0, 2)\n",
    "SF0 = d['SF'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same filtering criteria as in Sane et al. (2023)\n",
    "ind101 = np.where(np.abs(heat0) < 601)[0]\n",
    "ind1 = ind101\n",
    "ind2 = np.where(tx0 < 1.2)[0]\n",
    "ind3 = np.where(h0 > 29)[0]\n",
    "ind4 = np.where(h0 < 301)[0]\n",
    "\n",
    "# Combine all filters\n",
    "ind5 = np.intersect1d(ind1, ind2)\n",
    "ind6 = np.intersect1d(ind3, ind5)\n",
    "ind7 = np.intersect1d(ind4, ind6)\n",
    "\n",
    "# Prepare data for model training\n",
    "mm1 = 0; mm2 = 16  # 16 levels (level 1 at bottom, level 16 at top)\n",
    "data_load_main = np.zeros([len(h0[ind7]), 4 + mm2 - mm1])\n",
    "data_load_main[:, 0] = l0[ind7]     # Coriolis parameter\n",
    "data_load_main[:, 1] = b00[ind7]    # Surface buoyancy flux\n",
    "data_load_main[:, 2] = ustar0[ind7] # Surface friction velocity\n",
    "data_load_main[:, 3] = h0[ind7]     # Boundary layer depth\n",
    "data_load_main[:, 4:(mm2 - mm1 + 4)] = SF0[ind7, mm1:mm2] # Shape functions\n",
    "\n",
    "# Store additional forcing variables for reference\n",
    "data_forc = np.zeros([len(ind7), 3])\n",
    "data_forc[:, 0] = lat0[ind7]  # Latitude\n",
    "data_forc[:, 1] = heat0[ind7] # Heat flux\n",
    "data_forc[:, 2] = tx0[ind7]   # Wind stress\n",
    "\n",
    "# Create a copy of the data for processing\n",
    "data_load3 = copy.deepcopy(data_load_main)\n",
    "\n",
    "# Preprocess data using the same function as in the original code\n",
    "print('Preprocessing data...')\n",
    "data, x, y, stats, k_mean, k_std = ff.preprocess_train_data(data_load3)\n",
    "print('Done preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "url = \"https://nyu1.osn.mghpcc.org/leap-pangeo-manual/GOTM/data_testing_4_paper.txt\"\n",
    "df = pd.read_csv(url, delim_whitespace=True, header=None)\n",
    "valid_data = df.iloc[:, 3:].values\n",
    "\n",
    "# Apply same filtering criteria\n",
    "ind3 = np.where(valid_data[:, 3] > 29)[0]\n",
    "ind4 = np.where(valid_data[:, 3] < 301)[0]\n",
    "ind = np.intersect1d(ind3, ind4)\n",
    "\n",
    "# Extract and normalize validation features\n",
    "valid_x_np = valid_data[ind, 0:4]\n",
    "valid_x_np[:, 0] = (valid_x_np[:, 0] - stats[0]) / stats[1]  # Normalize Coriolis\n",
    "valid_x_np[:, 1] = (valid_x_np[:, 1] - stats[2]) / stats[3]  # Normalize buoyancy flux\n",
    "valid_x_np[:, 2] = (valid_x_np[:, 2] - stats[4]) / stats[5]  # Normalize friction velocity\n",
    "valid_x_np[:, 3] = (valid_x_np[:, 3] - stats[6]) / stats[7]  # Normalize layer depth\n",
    "\n",
    "# Extract and normalize validation targets\n",
    "valid_y_np = valid_data[ind, 5:]\n",
    "for i in range(len(valid_y_np)):\n",
    "    valid_y_np[i, :] = np.log(valid_y_np[i, :] / np.max(valid_y_np[i, :]))\n",
    "for i in range(16):\n",
    "    valid_y_np[:, i] = (valid_y_np[:, i] - k_mean[i]) / k_std[i]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "valid_x = torch.FloatTensor(valid_x_np).to(device)\n",
    "valid_y = torch.FloatTensor(valid_y_np).to(device)\n",
    "\n",
    "print(f\"Training data shape: {x.shape}, {y.shape}\")\n",
    "print(f\"Validation data shape: {valid_x.shape}, {valid_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the Baseline Model\n",
    "\n",
    "We'll first train a single baseline model on all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "model_params = {\n",
    "    'in_nodes': 4,      # 4 input features\n",
    "    'hidden_nodes': 32, # 32 nodes per hidden layer\n",
    "    'out_nodes': 16,    # 16 output points\n",
    "    'dropout_rate': 0.25  # Dropout for regularization\n",
    "}\n",
    "\n",
    "# Create the baseline model\n",
    "baseline_model = OceanMixingNN(**model_params).to(device)\n",
    "\n",
    "# Create a simplified BaseClusteredModel for the baseline (just for consistent API)\n",
    "class BaselineModel(InputClusteredModel):\n",
    "    def __init__(self, model_class, model_params):\n",
    "        super().__init__(model_class, model_params, n_clusters=1)\n",
    "        \n",
    "    def fit(self, X, y, valid_X=None, valid_y=None, stats=None):\n",
    "        # Convert to tensors if needed\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X_tensor = torch.FloatTensor(X).to(self.device)\n",
    "        else:\n",
    "            X_tensor = X.to(self.device)\n",
    "            \n",
    "        if isinstance(y, np.ndarray):\n",
    "            y_tensor = torch.FloatTensor(y).to(self.device)\n",
    "        else:\n",
    "            y_tensor = y.to(self.device)\n",
    "        \n",
    "        # Store stats\n",
    "        self.stats = stats\n",
    "        \n",
    "        # Initialize model\n",
    "        model = self.model_class(**self.model_params).to(self.device)\n",
    "        \n",
    "        # Train a single model on all data\n",
    "        print(\"Training baseline model on all data...\")\n",
    "        trained_model, losses = self._train_model(\n",
    "            model=model,\n",
    "            X=X_tensor,\n",
    "            y=y_tensor,\n",
    "            valid_X=valid_X,\n",
    "            valid_y=valid_y,\n",
    "            stats=stats\n",
    "        )\n",
    "        \n",
    "        # Store in cluster_models[0] for consistent API\n",
    "        self.cluster_models[0] = {\n",
    "            'model': trained_model,\n",
    "            'losses': losses\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Convert to tensor if needed\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X_tensor = torch.FloatTensor(X).to(self.device)\n",
    "        else:\n",
    "            X_tensor = X.to(self.device)\n",
    "        \n",
    "        # Use the single model for all predictions\n",
    "        model = self.cluster_models[0]['model']\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_tensor)\n",
    "        \n",
    "        # Return predictions and dummy cluster assignments (all 0)\n",
    "        dummy_clusters = np.zeros(len(X), dtype=int)\n",
    "        return preds, dummy_clusters\n",
    "\n",
    "# Create and train the baseline model\n",
    "baseline = BaselineModel(OceanMixingNN, model_params)\n",
    "baseline.fit(x, y, valid_x, valid_y, {'k_mean': k_mean, 'k_std': k_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training losses for the baseline model\n",
    "visualizer = ClusterModelVisualizer()\n",
    "visualizer.plot_losses(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline model\n",
    "baseline_metrics = baseline.evaluate(\n",
    "    valid_x, valid_y, {'k_mean': k_mean, 'k_std': k_std}\n",
    ")\n",
    "\n",
    "print(f\"Baseline overall MAE: {baseline_metrics['mae']:.6f}\")\n",
    "print(\"\\nBaseline node-wise MAE:\")\n",
    "for i, mae in enumerate(baseline_metrics['node_mae']):\n",
    "    print(f\"Layer {i+1}: {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Input-Based Clustering Approach\n",
    "\n",
    "Now we'll cluster based on the input features and train separate models for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input clustered model\n",
    "input_clustered = InputClusteredModel(\n",
    "    model_class=OceanMixingNN,\n",
    "    model_params=model_params,\n",
    "    n_clusters=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "input_clustered.fit(\n",
    "    X=x,\n",
    "    y=y,\n",
    "    valid_X=valid_x,\n",
    "    valid_y=valid_y,\n",
    "    stats={'k_mean': k_mean, 'k_std': k_std}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "feature_names = ['Coriolis', 'Buoyancy Flux', 'Friction Velocity', 'Layer Depth']\n",
    "visualizer.plot_clusters(input_clustered, valid_x_np, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training losses for each cluster\n",
    "visualizer.plot_losses(input_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate input clustered model\n",
    "input_clustered_metrics = input_clustered.evaluate(\n",
    "    valid_x, valid_y, {'k_mean': k_mean, 'k_std': k_std}\n",
    ")\n",
    "\n",
    "print(f\"Input Clustered overall MAE: {input_clustered_metrics['mae']:.6f}\")\n",
    "print(\"\\nCluster-wise MAE:\")\n",
    "for cluster_id, mae in input_clustered_metrics['cluster_mae'].items():\n",
    "    print(f\"Cluster {cluster_id}: {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline and input clustered model performance\n",
    "visualizer.plot_performance_comparison(baseline_metrics, input_clustered_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Shape Function (Output) Clustering Approach\n",
    "\n",
    "Now we'll implement the more innovative approach of clustering based on the output shape functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output clustered model\n",
    "output_clustered = OutputClusteredModel(\n",
    "    model_class=OceanMixingNN,\n",
    "    model_params=model_params,\n",
    "    n_clusters=4,\n",
    "    random_state=42,\n",
    "    use_pca=True,\n",
    "    n_components=5\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "output_clustered.fit(\n",
    "    X=x,\n",
    "    y=y,\n",
    "    valid_X=valid_x,\n",
    "    valid_y=valid_y,\n",
    "    stats={'k_mean': k_mean, 'k_std': k_std}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the shape function clusters\n",
    "visualizer.plot_shape_functions(output_clustered, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance for predicting shape clusters\n",
    "visualizer.plot_clusters(output_clustered, x, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training losses for each shape cluster\n",
    "visualizer.plot_losses(output_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate output clustered model\n",
    "output_clustered_metrics = output_clustered.evaluate(\n",
    "    valid_x, valid_y, {'k_mean': k_mean, 'k_std': k_std}\n",
    ")\n",
    "\n",
    "print(f\"Output Clustered overall MAE: {output_clustered_metrics['mae']:.6f}\")\n",
    "print(\"\\nShape Cluster-wise MAE:\")\n",
    "for cluster_id, mae in output_clustered_metrics['cluster_mae'].items():\n",
    "    print(f\"Shape Cluster {cluster_id}: {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline and output clustered model performance\n",
    "visualizer.plot_performance_comparison(baseline_metrics, output_clustered_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing All Approaches\n",
    "\n",
    "Let's compare all three approaches: baseline, input clustering, and output clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare overall performance\n",
    "plt.figure(figsize=(10, 6))\n",
    "models = ['Baseline', 'Input Clustered', 'Output Clustered']\n",
    "mae_values = [\n",
    "    baseline_metrics['mae'],\n",
    "    input_clustered_metrics['mae'],\n",
    "    output_clustered_metrics['mae']\n",
    "]\n",
    "colors = ['blue', 'orange', 'green']\n",
    "\n",
    "# Create bar chart\n",
    "bars = plt.bar(models, mae_values, color=colors, alpha=0.7)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.6f}',\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "# Calculate improvement percentages\n",
    "input_improvement = (baseline_metrics['mae'] - input_clustered_metrics['mae']) / baseline_metrics['mae'] * 100\n",
    "output_improvement = (baseline_metrics['mae'] - output_clustered_metrics['mae']) / baseline_metrics['mae'] * 100\n",
    "\n",
    "# Add improvement annotations\n",
    "plt.annotate(f'{input_improvement:.2f}% improvement', \n",
    "            xy=(1, input_clustered_metrics['mae']),\n",
    "            xytext=(1, (baseline_metrics['mae'] + input_clustered_metrics['mae'])/2),\n",
    "            arrowprops=dict(arrowstyle='->', color='orange'),\n",
    "            ha='center', va='center', fontsize=12,\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "\n",
    "plt.annotate(f'{output_improvement:.2f}% improvement', \n",
    "            xy=(2, output_clustered_metrics['mae']),\n",
    "            xytext=(2, (baseline_metrics['mae'] + output_clustered_metrics['mae'])/2),\n",
    "            arrowprops=dict(arrowstyle='->', color='green'),\n",
    "            ha='center', va='center', fontsize=12,\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Overall Performance Comparison')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare node-wise performance\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(16)  # 16 vertical levels\n",
    "width = 0.25       # width of the bars\n",
    "\n",
    "# Create grouped bar chart\n",
    "plt.bar(x - width, baseline_metrics['node_mae'], width, label='Baseline', color='blue', alpha=0.7)\n",
    "plt.bar(x, input_clustered_metrics['node_mae'], width, label='Input Clustered', color='orange', alpha=0.7)\n",
    "plt.bar(x + width, output_clustered_metrics['node_mae'], width, label='Output Clustered', color='green', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Vertical Level')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Node-wise Error Comparison')\n",
    "plt.xticks(x, [f'L{i+1}' for i in range(16)])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "The class-based architecture provides a clean, flexible way to implement and compare different clustering approaches for ocean mixing parameterization. Key takeaways:\n",
    "\n",
    "1. **Both Clustering Approaches Improve Performance**: Both input-based and output-based clustering outperform the baseline model.\n",
    "\n",
    "2. **Shape Function Clustering**: Clustering directly on shape functions represents a more physically-motivated approach and shows promising results.\n",
    "\n",
    "3. **Flexible Architecture**: The modular design makes it easy to experiment with different clustering algorithms, model architectures, and training parameters.\n",
    "\n",
    "4. **Enhanced Interpretability**: Visualization tools help understand the physical meaning of clusters and their performance characteristics.\n",
    "\n",
    "This notebook provides a foundation for further experimentation with clustered approaches to ocean mixing parameterization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}